\chapter{Introducción}
\pagenumbering{arabic}

\section{Motivación}

La inteligencia artificial (IA) gana cada año mas popularidad, impulsada por los últimos avances en tecnología y su aplicación en diversas industrias. La Figura \ref{fig:ai_grow} muestra el porcentaje de empresas que muestran interés en la IA y en la Figura \ref{fig:ai_market_size} se representa el crecimiento del valor del mercado de la IA en miles de millones de dolares.

% Vertically alling two sufigures and keep subcaption using floatrow and subcaptions pkgs
\begin{figure}[htb]
  \floatsetup{heightadjust=all, valign=c}
  \begin{subcaptiongroup}
  \begin{floatrow}
    \ffigbox{%
      \includegraphics[width=0.48\textwidth]{root/Imagenes/1_intro/ai_interest.png}
    }{%
      \caption{Interés de las empresas, representado mediante el porcentaje de empresas \cite{ai_interest_growth}.}
      \label{fig:ai_grow}
    }
    \ffigbox{%
      \includegraphics[width=0.49\textwidth]{root/Imagenes/1_intro/market_size.png}
    }{%
      \caption{Valor de mercado en miles de millones de dolares \cite{ai_market_size}.}
      \label{fig:ai_market_size}
    }
  \end{floatrow}
  \end{subcaptiongroup}
  \caption{Crecimiento de la IA en los últimos 10 años y crecimiento esperado hasta 2030.}%
\end{figure}

Al aumentar este interés y por tanto su uso en diversos campos también lo hará el consumo energético. La motivación principal de este trabajo es desarrollar componentes hardware para aumentar la eficiencia energética de la inferencia en un subconjunto de técnicas de aprendizaje automático. Concretamente, este trabajo se centra en las redes neuronales bayesianas (\textit{\textbf{B}ayesian \textbf{N}eural \textbf{N}etwork}). Estas redes calculan la incertidumbre de sus predicciones aportando transparencia en su uso. En relación, otra de las motivaciones de este trabajo es facilitar la adopción de estas redes para ayudar hacia el objetivo de la Unión Europea de trabajar con IAs más transparentes \cite{eu_ai}. Otra de las motivaciones principales de este trabajo es fomentar el desarrollo de la arquitectura RISC-V, que es una arquitectura de procesadores abierta y libre. Europa ha apostado por esta arquitectura, mediante el proyecto el \textit{European Processor Initiative} (EPI) \cite{european_processor}, para que sus empresas puedan diseñar y producir sus propios procesadores sin las restricciones y costos asociados con las arquitecturas propietarias tradicionales. 

Específicamente, este TFM aborda la ejecución de la inferencia de BNNs en dispositivos de bajas prestaciones orientados hacia la internet de las cosas (\textit{\textbf{I}nternet \textbf{o}f \textbf{T}hings}). Esta combinación se conoce comúnmente como TinyML y tiene un gran potencial a la hora de reducir el consumo energético \cite{tinyML_sustainable}. Los componentes IoT son mas eficientes energéticamente que los procesadores de altas prestaciones, por lo que trasladar la ejecución de la inferencia de BNN a estos componentes reduciría su consumo además de eliminar comunicaciones costosas entre componentes IoT desplegados y servidores.

\section{Objetivos y alcance}

El objetivo principal de este trabajo es optimizar la inferencia de BNN en un procesador RISC-V de bajas prestaciones. Se han seguido los siguientes pasos para lograr el objetivo:
\begin{enumerate}
    \item Estudiar el funcionamiento de la inferencia de las BNN.
    \item Analizar aceleradores existentes de inferencia de BNN.
    \item Investigar el soporte existente para ejecutar inferencia de BNN en procesadores de bajas prestaciones sin precisión de punto flotante.
    \item Implementar una biblioteca en C junto a herramientas que permitan ejecutar la inferencia de BNN en un procesador RISC-V desarrollado en un trabajo previo \cite{riscv_tfg}.
    \item Validar la biblioteca implementada con diferentes modelos.
    \item Analizar la carga de trabajo de la biblioteca desarrollada.
    \item Desarrollar optimizaciones software y analizar sus ventajas y desventajas.
    \item Investigar sobre generadores de números aleatorios gaussianos (\textit{\textbf{G}aussian \textbf{R}andom \textbf{N}umber \textbf{G}enerator}).
    \item Diseñar un GRNG que se pueda integrar en el procesador RISC-V como una extensión.
    \item Estudiar los pasos necesarios para extender un procesador RISC-V y poder utilizar la extensión desde código en alto nivel C.
    \item Analizar el coste y rendimiento de la extensión utilizando una \textit{Field Programmable Gate Array} (FPGA).
\end{enumerate}

Todo el código de este trabajo se encuentra disponible en un repositorio público en GitHub \cite{bnn_github}.

%% quizas aqui se puede poner que lo hemos enviado al congreso y las JJI

\section{Estructura del documento}

\todo La siguiente sección explica las herramientas que se han utilizado para completar este trabajo. El Capítulo 2 describe la metodología que se ha segundo durante el desarrollo del trabajo y herramientas utilizadas. El Capítulo 3 describe el estado del arte relacionado con la arquitectura RISC-V y las BNN. El Capítulo 4 muestra los componentes desarrollados para ejecutar inferencia de BNN en plataformas RISC-V y los resultados obtenidos. El Capítulo 5 explica como se ha implementado una extensión para la inferencia de BNN en un procesador RISC-V y los resultados que se han obtenido. Por último el Capitulo 6 contiene las conclusiones del trabajo.

